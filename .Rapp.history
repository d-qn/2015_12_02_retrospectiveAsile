str(data)
head(data)
colnames(data) <- c('GHSTNR', 'BHSTNR', 'KTKZ', 'GBFSNR', 'GNAME', 'GNAMK', 'GARTE', #
                      'GSTAT', 'GINIMUT', 'GINIART', 'GINIDAT', 'GFINMUT', 'GFINART', #
                      'GFINDAT','GMUTDAT')
str(data)
asDate(data$GINIDAT)
as.Date(data$GINIDAT)
as.date
?as.Date
as.Date(data$GINIDAT, format = "%d.%m.%Y")
str(data)
as.Date(data$GINIDAT, format = "%d.%m.%Y")
data$GINIDAT <- as.Date(data$GINIDAT, format = "%d.%m.%Y")#
  data$GFINDAT <- as.Date(data$GFINDAT, format = "%d.%m.%Y")#
  data$GMUTDAT <- as.Date(data$GMUTDAT, format = "%d.%m.%Y")
str(data)
min(data$GINIDAT)
str(min(data$GINIDAT))
as.Date("1960-01-01")
today()
date()
?date()
Sys.Date()
"2012-01-01"
Sys.Date()
start <- as.Date(start)#
  end <- as.Date(end)
start
start<- "2012-01-01"
end <- Sys.Date()
start <- as.Date(start)#
  end <- as.Date(end)
start
end
str(data)
data$GFINDAT
data$GFINDAT >= start
which(data$GFINDAT >= start)
data[which(data$GFINDAT >= start),]
?encoding
?Encoding
data.path <- dir(system.file("extdata", package="swiMap"), "GDEHist_GDE\\.txt", full.names = T)#
  data <- read.csv(data.path, sep ="\t",  header = FALSE, stringsAsFactors = F, encoding = "latin1")#
  # colnames#
  colnames(data) <- c('GHSTNR', 'BHSTNR', 'KTKZ', 'GBFSNR', 'GNAME', 'GNAMK', 'GARTE', #
                      'GSTAT', 'GINIMUT', 'GINIART', 'GINIDAT', 'GFINMUT', 'GFINART', #
                      'GFINDAT','GMUTDAT')#
  # tranform to dates#
  data$GINIDAT <- as.Date(data$GINIDAT, format = "%d.%m.%Y")#
  data$GFINDAT <- as.Date(data$GFINDAT, format = "%d.%m.%Y")#
  data$GMUTDAT <- as.Date(data$GMUTDAT, format = "%d.%m.%Y")
data[which(data$GFINDAT >= start),]
data[which(data$GFINDAT >= start & data$GINIART == 24),]
data[which(data$GFINDAT >= start & data$GINIART == 26),]
data[which(data$GFINDAT >= start || data$GINIDAT >= start),]
data[which(data$GFINDAT >= start | data$GINIDAT >= start),]
data[which(data$GFINDAT >= start & data$GINIART == 26),]
start
data[which(data$GFINDAT >= start & data$GINIART == 26),'GFINMUT']
data$GFINMUT %in% data[which(data$GFINDAT >= start & data$GINIART == 26),'GINITMUT']
which(data$GFINMUT %in% data[which(data$GFINDAT >= start & data$GINIART == 26),'GINITMUT'])
data[which(data$GFINDAT >= start & data$GINIART == 26),'GFINMUT']
data[which(data$GFINDAT >= start & data$GINIART == 26),]
data[which(data$GFINDAT >= start & data$GINIART == 24),]
which(data$GINIMUT == 3404)
data[which(data$GINIMUT == 3404),]
data[which(data$GFINDAT >= start | data$GINIDAT >= start),]
data[which((data$GFINDAT >= start | data$GINIART >= start) & (data$GFINDAT <= end | data$GINIART <= end)),]
data[which((data$GFINDAT >= start | data$GINIART >= start),]
data[which(data$GFINDAT >= start | data$GINIART >= start),]
data[which(data$GINIMUT == 3404),]
data[which(data$GFINDAT >= start | data$GINIART >= start),]
test<- data[which(data$GFINDAT >= start | data$GINIART >= start),]
data[which(data$GFINDAT >= start | data$GINIART >= start),]
data[which(data$GINIMUT == 3404),]
test
data[which(data$GINIMUT == 3404),]
any(test$GINIMUT == 3404)
summary(data$GFINDAT)
T | NA
NA | T
data[which((data$GFINDAT >= start | data$GINIDAT >= start) & (data$GFINDAT <= end | data$GINIDAT <= end)),]
library(swiTheme)
?multiplot
q1 <- qplot(1:10, 1:10, size = 10:1) + xlab("axis x label") + ylab ("y axis label") + theme_swi2()#
q2 <- qplot(mpg, data = mtcars, geom = "dotplot") + theme_swi()#
multiplot(list(q1, q2))
library(leaflet)
(m <- leaflet() %>% addTiles())
m %>% setView(lng = -1.5, lat = 53.4, zoom = 10) # set centre and extent of map
(m2 <- m %>%#
  setView(-1.5, 53.4, 10) %>% # map location#
  addMarkers(-1.4, 53.5) %>% # add a marker#
  addPopups(-1.6, 53.3, popup = "Hello Sheffield!") %>% # popup#
  # add som circles:#
  addCircles(color = "black", runif(90, -2, -1), runif(90, 53, 54), runif(90, 10, 500)))
library(leaflet)#
m = leaflet() %>% addTiles()
m
? addTiles
library(leaflet)#
m = leaflet() %>% addTiles()
m
m %>% setView(lng = -1.5, lat = 53.4, zoom = 10)
?leaflet
?leafletOutput
(m2 <- m %>%#
  setView(-1.5, 53.4, 10) %>% # map location#
  addMarkers(-1.4, 53.5) %>% # add a marker#
  addPopups(-1.6, 53.3, popup = "Hello Sheffield!") %>% # popup#
  # add som circles:#
  addCircles(color = "black", runif(90, -2, -1), runif(90, 53, 54), runif(90, 10, 500)))
? renderLeaflet
?leafletMap
?leafletOutput
?publish
publish
save
?save
m2
save(m2)
save(m2, "test")
save(m2, file = "test")
getwd()
? html_print
? toHTML
library(streamgraph)#
library(dplyr)#
ggplot2::movies %>%#
  select(year, Action, Animation, Comedy, Drama, Documentary, Romance, Short) %>%#
  tidyr::gather(genre, value, -year) %>%#
  group_by(year, genre) %>%#
  tally(wt=value) %>%#
  streamgraph("genre", "n", "year") %>%#
  sg_axis_x(20) %>%#
  sg_colors("PuOr") %>%#
  sg_legend(show=TRUE, label="Genres: ")
saveWidget
library(rgdal)#
library(leaflet)#
#
tmp <- tempdir()#
#
url <- "http://personal.tcu.edu/kylewalker/data/mexico.zip"#
#
file <- basename(url)#
#
download.file(url, file)#
#
unzip(file, exdir = tmp)#
#
mexico <- readOGR(dsn = tmp, layer = "mexico", encoding = "UTF-8")
library("swiTheme")#
library("swiRcharts")#
library("dplyr")#
library("rjson")#
#
#############################################################################################
###		SETTINGS	#
#############################################################################################
#
votefile <- "data/VOTEScsv_cleaned.csv"#
#
#############################################################################################
###		load initiative data	#
#############################################################################################
#
initiatives.read <- read.csv(votefile, check.names = F, stringsAsFactors = F, encoding = "latin1")#
#
# reverse order #
initiatives.read <- initiatives.read[rev(as.numeric(rownames(initiatives.read))),]#
#
# filter columns#
initiatives <- initiatives.read %>% select(`Date of Votes`, `Title in English`, `Title in German`, `Title in French`, `Title in Italien`, `Yes [%]`, `Theme codes`)#
# transform date to date#
initiatives$date <- as.Date(initiatives$`Date of Votes`)#
#
initiatives$year <- as.numeric(substr(initiatives$`Date of Votes`,1, 4))#
# add counter iniitiative per year #
initiatives <- do.call(rbind, by(initiatives, initiatives$year, function(ii) {#
	cbind(ii, n = nrow(ii):1)#
}))#
#############################################################################################
###		Plot#
#############################################################################################
#
## PLOT SETTINGS#
plot.height <- 350#
#
data <- initiatives %>% select (`Title in English`, `year`, `n`,  `Yes [%]`)#
colnames(data) <- c('name', 'y', 'x', 'value')#
#
a <- Highcharts$new()#
#
# use type='heatmap' for heat maps#
a$chart(zoomType = "x", type = 'heatmap', height = plot.height, plotBackgroundColor = "#f7f5ed", inverted = TRUE)#
a$series( data = rCharts::toJSONArray2(data, json = F, names = T))#
#
a$addParams(colorAxis =#
  list(min = 0, max = 100, stops = list(#
	  list(0, '#ab3d3f'),#
      list(0.499, '#EED8D9'),	  #
      list(0.5, '#999966'),#
      list(1, '#336666') #
  ))#
)#
#
# a$legend(align='right',#
#          layout='vertical',#
#          margin=0,#
#          verticalAlign='top',#
#          y=25,#
#          symbolHeight=plot.height)#
a$yAxis(max = max(data$y), ceiling = max(data$y), maxPadding = 0, tickAmount = 2, gridLineWidth =  0, minorGridLineWidth = 0, title = list(text = ""))#
#
a$xAxis(lineWidth = 0, minorGridLineWidth = 0, lineColor = 'transparent', labels = list(enabled = FALSE), #
	minorTickLength = 0, tickLength =  0)  	#
a$tooltip(formatter = "#! function() { return 'In <b>' + this.point.y + ',</b> the initative:<br><i>' + this.point.name +#
                    '</i><br>recolted <b>' + this.point.value + '%</b> of yes'; } !#")	 #
a$legend(enabled = F)#
a$addAssets(js =#
   c(#"https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js",#
     # "https://code.highcharts.com/highcharts.js",#
     # "https://code.highcharts.com/highcharts-more.js",#
     "https://code.highcharts.com/modules/exporting.js",#
     "https://code.highcharts.com/modules/heatmap.js"#
     )#
)#
a#
#
a$save(destfile = 'initiative.html')#
#
hChart2responsiveHTML("initiative.html", output.html = "initiative_heatmap.html", h2 = "Toutes les initiatives populaires suisses", descr = "",#
	source = "", h3 = "", author = "Duc-Quang Nguyen | swissinfo.ch")
library(swiRchart)
library(swiRcharts)
?hSeries
ibrary(swiTheme)#
a <- rCharts::Highcharts$new()#
x <- 1:10#
y <- seq(1, 100, 10)#
z <- 10:1#
color <- rep(c("grey", "red"), 5)#
name <- c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j")#
series <- c(rep(c("blob", "poop", "doop"), 3), "asdf")#
a$series(hSeries(x,y,z,name, color, series))#
#
# tweak the bubble plot#
a$chart(zoomType = "xy", type = "bubble")#
a$plotOptions(bubble = list(dataLabels = list(enabled = T, style = list(textShadow = 'none') ,#
color = '#aa8959', formatter = "#! function() { return this.point.name; } !#")))#
#
a$colors(swi_rpal)#
a$tooltip(formatter = "#! function() { return this.point.name + ':' +this.x + ', ' + this.y; } !#")#
a$xAxis(title = list(text = "important indicator", align = "high"), lineColor = list ('#FF0000'))#
a#
#
hChart.html <- tempfile("hchart_labelledBubble.html")#
a$save(hChart.html)
library(swiRchart)
library(swiRcharts)
?hSeries
library(swiTheme)#
a <- rCharts::Highcharts$new()#
x <- 1:10#
y <- seq(1, 100, 10)#
z <- 10:1#
color <- rep(c("grey", "red"), 5)#
name <- c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j")#
series <- c(rep(c("blob", "poop", "doop"), 3), "asdf")#
a$series(hSeries(x,y,z,name, color, series))
a$chart(zoomType = "xy", type = "bubble")#
a$plotOptions(bubble = list(dataLabels = list(enabled = T, style = list(textShadow = 'none') ,#
color = '#aa8959', formatter = "#! function() { return this.point.name; } !#")))#
#
a$colors(swi_rpal)#
a$tooltip(formatter = "#! function() { return this.point.name + ':' +this.x + ', ' + this.y; } !#")#
a$xAxis(title = list(text = "important indicator", align = "high"), lineColor = list ('#FF0000'))#
a#
#
hChart.html <- tempfile("hchart_labelledBubble.html")#
a$save(hChart.html)
hChart2responsiveHTML
library(swiRcharts)
?hSeries
library(swiTheme)#
a <- rCharts::Highcharts$new()#
x <- 1:10#
y <- seq(1, 100, 10)#
z <- 10:1#
color <- rep(c("grey", "red"), 5)#
name <- c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j")#
series <- c(rep(c("blob", "poop", "doop"), 3), "asdf")#
a$series(hSeries(x,y,z,name, color, series))
hSeries2 <- hSeries2(data.frame(x = x, y = y, z = z, color = color, name = name, series = series), "series")#
 b <- rCharts::Highcharts$new()#
b$series(hSeries2)
b
install.packages("readr")
install.package("devtools")
install.packages("devtools")
install.packages("rCharts")
install.packages("devtools")#
require(devtools)#
install_github('rCharts', 'ramnathv')#
library(rCharts)
install_github(ramnathv/rCharts)
1:2
rev(1:2)
library(rCharts)
set.seed(123134)#
y <- rnorm(20, 35, 4)#
y[7] <- NA#
y[13] <- NA#
y <- rbind(t(t(y)), t(t(rep(NA, 10))))#
fc <- rnorm(10, 35, 1)#
fc <- rbind(t(t(rep(NA,20))), t(t(fc)))#
uci <- rnorm(10, 38, 1)#
uci <- rbind(t(t(rep(NA,20))), t(t(uci)))#
lci <- rnorm(10, 32, 1)#
lci <- rbind(t(t(rep(NA,20))), t(t(lci)))#
plotData <- data.frame(y,fc,uci,lci)#
#
h1 <- Highcharts$new()#
h1$chart(type="line")#
h1$series(data=plotData$y, marker = list(symbol = 'circle'), connectNulls = TRUE)#
h1$series(data=plotData$fc, marker = list(symbol = 'circle'), connectNulls = TRUE)#
h1$series(data=plotData$uci, showInLegend = FALSE, marker = list(symbol = 'square'), connectNulls = TRUE)#
h1$series(data=plotData$lci, showInLegend = FALSE, marker = list(symbol = 'square'), connectNulls = TRUE)#
h1$series(data=rep(30,30), marker= list(enabled = FALSE))#
h1
257508 / 20524
library(swiMap)
test <- loadCommunesCHportraits()
loadCommunesCHportraits
3700 / 67.2
3.700 / 67.2
6 * 254
6 * 25
install.packages("gridSVG")
c(640, 610,840 ,860, 1240 ,1345, 1065, 1305)
sum(c(640, 610,840 ,860, 1240 ,1345, 1065, 1305))
sum(c(840 ,860, 1240 ,1345, 1065, 1305))
c(1565, 1425, 1500, 1375, 2205, 3805)
sum(c(1565, 1425, 1500, 1375, 2205, 3805))
11875 / 8000000
50000*(11875 / 8000000 )
load("/Users/nguyendu/Google Drive/swissinfo/2015_06_24_euroAsylum/prod/data/02_citizenMonthly_waffled_new.Rdata")
str(data)
data
ls()
dd
library(dplyr)
50000*(11875 /7364148 )
library(streamgraph)#
library(dplyr)#
library(babynames)#
library(DT)#
#
ggplot2::movies %>%#
  select(year, Action, Animation, Comedy, Drama, Documentary, Romance, Short) %>%#
  tidyr::gather(genre, value, -year) %>%#
  group_by(year, genre) %>%#
  tally(wt=value) -> dat#
#
streamgraph(dat, "genre", "n", "year", interactive=TRUE) %>%#
  sg_axis_x(20, "year", "%Y") %>%#
  sg_fill_brewer("PuOr")
install.packages("networkD3")
library("networkD3")
?sankeyNetwork
?sankeyNetworkOutput
devtools::install_github("timelyportfolio/parsetR")
library(parsetR)#
parset(Titanic)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.5, width = "80%", height = 400)
? parset
UCBAdmissions
str(UCBAdmissions)
head(UCBAdmissions)
str(UCBAdmissions)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.5, width = "100%", height = 400)
?parset
library(parsetR)#
#
parset(UCBAdmissions, tension = 0, width = "100%", height = 400)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.9, width = "100%", height = 400)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.4, width = "100%", height = 400)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.3, width = "100%", height = 400)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.7, width = "100%", height = 400)
library(parsetR)#
#
parset(UCBAdmissions, tension = 0.4, width = "100%", height = 400)
?table
is.list(UCBAdmissions)
?select
UCBAdmissions
UCBAdmissions$admit
UCBAdmissions[1]
UCBAdmissions[1,1,1]
UCBAdmissions[1]
UCBAdmissions[2]
UCBAdmissions[15]
UCBAdmissions[182]
UCBAdmissions[18]
UCBAdmissions[45]
length(UCBAdmissions)
?subset
length(UCBAdmissions)
str(UCBAdmissions)
subset(UCBAdmissions, c('Gender', "Dept"))
subset(UCBAdmissions, c(T,F))
subset(UCBAdmissions, c(T))
subset(UCBAdmissions, c(T, F))
subset(UCBAdmissions, c(T, F, T))
subset(UCBAdmissions, c(T, F, T, T))
54 + 46 + 30 + 28 + 15 + 12 + 9
194 / 200
library(swiMap)
parseSVG <- function(input = NULL) {#
  if(!file.exists(input)) stop (input, " cannot be found")#
  if(!grepl("\\.svg$", input)) stop(input, " needs to be a svg file")#
  xmlTreeParse(input, useInternalNodes = T)#
}#
#
parseTxt <- function(xmlTree) {#
  # get all the tspan within text elements#
  # I don't really understand the parsing, adapted from: http://www.omegahat.org/SVGAnnotation/SVGAnnotationPaper/SVGAnnotationPaper.html#bib:XPathXPointer#
  getNodeSet(xmlTree, "//x:text/x:tspan", "x")#
}#
#
get_nonNumericNonEmptyString <- function(textNodes) {#
  # Get the index of text which are not empty and not only numeric#
  !sapply(textNodes, xmlValue) %in% c("", " ", "\n") & !grepl("^\\d+$", sapply(textNodes, xmlValue)) & sapply(textNodes, xmlSize) == 1#
}#
#
get_NestedNonNumericNonEmptyString <- function(textNodes) {#
  # Get the index of text which are not empty and not only numeric#
  !sapply(textNodes, xmlValue) %in% c("", " ", "\n") & !grepl("^\\d+$", sapply(textNodes, xmlValue)) & sapply(textNodes, xmlSize) == 1#
}
library(XML)
svg <- system.file("extdata", "slopegraph_test.svg", package="swiMap")
svg
parseSVG(svg)
xmlt<- parseSVG(svg)
parseTxt(xmlt)
yparseTxt(xmlt)
nodet <- parseTxt(xmlt)
get_nonNumericNonEmptyString(nodet)
input <- svf
input <- svg
textNodes <- parseTxt(parseSVG(input))#
  idx <- get_nonNumericNonEmptyString(textNodes)#
  text.ori <- sapply(textNodes[idx], xmlValue)
text.ori
idx.nest <- which(sapply(textNodes, xmlSize) > 1)
idx.nest
text.ori <- c(text.ori, sapply(xmlChildren(textNodes[[idx.nest]]), xmlValue))
idx.nest
textNodes <- parseTxt(parseSVG(input))#
  idx <- get_nonNumericNonEmptyString(textNodes)#
  text.ori <- sapply(textNodes[idx], xmlValue)
idx.nest <- which(sapply(textNodes, xmlSize) > 1)
text.ori
?createTranslatedSVG
? theme_rect
w<-rnorm(100)#
x<-rnorm(100)#
y<-rnorm(100)#
z<-rnorm(100)#
g<-rep(factor(LETTERS[1:4]), 25)#
d<-data.frame(g,w,x,y,z)#
#
library(ggplot2)
p1 <- pw + geom_point() + facet_grid(.~g, scales='fixed') + coord_equal() +   #
      stat_smooth(method='lm')#
p2 <- px + geom_point() + facet_grid(.~g, scales='fixed') + coord_equal() + #
      stat_smooth(method='lm')#
p3 <- pz + geom_point() + facet_grid(.~g, scales='fixed') + coord_equal() +   #
      stat_smooth(method='lm')#
#
grid.arrange(p1, p2, p3, ncol=1)
library(gridExtra)
pw<-ggplot(d, aes(w, y))#
px<-ggplot(d, aes(x, y))#
pz<-ggplot(d, aes(z, y))
p1 <- pw + geom_point() + facet_grid(.~g, scales='fixed') + coord_equal() +   #
      stat_smooth(method='lm')#
p2 <- px + geom_point() + facet_grid(.~g, scales='fixed') + coord_equal() + #
      stat_smooth(method='lm')#
p3 <- pz + geom_point() + facet_grid(.~g, scales='fixed') + coord_equal() +   #
      stat_smooth(method='lm')#
#
grid.arrange(p1, p2, p3, ncol=1)
install_github("d-qn/_helpers/swiMap")
library("devtools")
install_github("d-qn/_helpers/swiMap")
? install_github
install_github("d-qn/_helpers/swiMap")
?install_github
install_github("d-qn/_helpers/", subdir = "swiMap")
install_github("d-qn/_helpers", subdir = "swiMap")
library("devtools")
install_github("d-qn/_helpers", subdir = "swiMap")
library(devtools)
install_github("d-qn/swiMap", subdir = "_helpers")
install_github("d-qn/_helpers", subdir = "swiMap")
install_github("d-qn/swiMap")
setwd('/Users/nguyendu/swissinfo/2015_12_02_retrospectiveAsile')
library(eurostat)#
library(dplyr)#
library(magrittr)#
######      This download the very large monthly asylum data with country of origin!#
dataID <- "migr_asyappctzm"#
#
data_2015.file <- "data/data_2015only.csv"#
data.sub.file <- "input/data.csv"#
#
#############################################################################################
###		Get data#
#############################################################################################
#
dat <- get_eurostat(dataID, time_format = "raw", cache = F)#
data <- cbind(label_eurostat(dat), iso2 = dat$geo)#
#
# transform dates efficiently!#
times <- unique(data$time)#
times <- structure(eurostat:::eurotime2date(times, last = FALSE), names = as.character(times))#
data$time <- times[match(data$time, names(times))]#
#
# subset columns#
data %<>% filter(asyl_app == 'Asylum applicant', sex == 'Total', age == 'Total') %>%#
	select(one_of(c('citizen', 'geo', 'time', 'values', 'iso2')))#
#
#write.csv(data, file = rawData.file,row.names = F)#
#
# subset the data for year 2015#
data %<>% filter(time >= as.Date("2015-01-01"))#
write.csv(data, file = data_2015.file, row.names = F)#
#
# consider only the months with full data (with NA less than 10%) !!#
times <- round(tapply(data$values, data$time, function(v) (sum(is.na(v))/length(v)) ) * 100)#
cat("% of missing country data by month\n")#
	### CHECK ####
## check CH value with http://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=migr_asyappctzm&lang=en#
data %>% filter(iso2 == 'CH', citizen == "Total")#
data %>% filter(iso2 == 'HU', citizen == "Total")#
data.all <- data#
#
#############################################################################################
###		Reshape: filter, aggregate#
#############################################################################################
#
citizenAgg <- c("Total", "European Union (28 countries)", "Extra EU-28")#
iso2agg <- c("EU28", "TOTAL")#
###		Aggregate data by geo & citizen#
data %<>% filter(!citizen %in% citizenAgg, !iso2 %in% iso2agg) %>%#
  group_by(iso2, geo, citizen) %>% dplyr::summarise(tot = sum(values, na.rm = T )) %>% ungroup()#
#
# remove coutry of origin always 0#
citToRemove <- as.character(unlist(data %>% group_by(citizen) %>% dplyr::summarise(grandTot = sum(tot, na.rm = T)) %>% filter(grandTot == 0) %>% select(citizen)))#
data %<>% filter(!citizen %in% citToRemove)#
### Get the top country of origins and destinations#
#
# find the n largest countries during the last year#
ntop <- 6#
#
sumByGeo <- data %>% group_by(iso2) %>% dplyr::summarise(sumByGeo = sum(tot, na.rm = T)) %>% ungroup()#
iso2.top <- as.character(unlist(head(as.data.frame(sumByGeo[order(sumByGeo$sumByGeo, decreasing = T),'iso2']), ntop)))#
iso2.top#
iso2.sub <- c('DE', 'CH', 'SE', 'HU', 'IT', 'FR', 'AT', 'UK')#
sumByCit <- data %>% group_by(citizen) %>% dplyr::summarise(sumByCit = sum(tot, na.rm = T)) %>% ungroup()#
cit.top <- as.character(unlist(head(as.data.frame(sumByCit[order(sumByCit$sumByCit, decreasing = T),'citizen']), ntop)))#
### Merge not top countries#
df <- data#
df$iso2 <- ifelse(as.character(df$iso2) %in% iso2.sub, as.character(df$iso2), 'other')#
df$citizen <- ifelse(as.character(df$citizen) %in% cit.top, as.character(df$citizen), 'Other countries')#
#
df %<>% group_by(iso2, citizen) %>% dplyr::summarise (values = sum(tot, na.rm = T)) %>% ungroup()#
# add back the country names to merged iso2#
df$geo <- as.character(unlist(data[match(df$iso2, data$iso2),'geo']))#
df[which(df$iso2 == "other"), 'geo'] <- "Other European countries"#
# drop unused levels#
df$citizen <- factor(df$citizen)#
df$iso2 <- factor(df$iso2)#
#
citLength <- unlist(unique(df %>% group_by(iso2) %>% dplyr::summarise(nelem = length(values)) %>% select(nelem)))#
geoLength <- unlist(unique(df %>% group_by(citizen) %>% dplyr::summarise(nelem = length(values)) %>% select(nelem)))#
#
stopifnot(geoLength == length(iso2.sub) + 1, citLength == ntop + 1)#
#
## tmp hack for long country names#
df$geo <- gsub(" \\(.*\\)$", "", df$geo)#
df$citizen <- gsub(" \\(.*\\)$", "", df$citizen)#
#
write.csv(df, file = data.sub.file, row.names = F)#
#
## get the total applications#
data.all %>% filter(iso2 == "TOTAL", citizen == "Total") %>% summarise(sum(values))#
# create the tmp translation file#
labels <- c(unique(df$citizen), unique(df$geo))#
write.csv(data.frame(code = paste0("code.", gsub(" ", "", labels)), en = labels), file = "input/translation_tmp.csv", row.names = F)
setwd('/Users/nguyendu/swissinfo/2015_12_02_retrospectiveAsile')
library(dplyr)#
library(parsetR)#
library(htmlwidgets)#
library(swiRcharts)#
#
###		SETTINGS   ####
data.sub.file <- "input/data.csv"#
translation.file <- "input/translation_asylumFlowsEU.csv"#
df <- read.csv(data.sub.file)#
txt <- read.csv(translation.file, row.names = 1, stringsAsFactors = F)#
for(lang in colnames(txt)) {#
  dd <- df#
#
  tmp_html <- paste0("flow_EU_tmp_", lang, ".html")#
  output.html <- paste0("asylumApplicationsFlow_EU_", lang, ".html")#
#
  # rename origin / citizen country names#
  idx <- match(paste0("code.", gsub(" ", "", dd$citizen)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$citizen <- txt[idx, lang]#
#
  # rename destination / geo names#
  idx <- match(paste0("code.", gsub(" ", "", df$geo)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$geo <- txt[idx, lang]#
#
  # rename dimensions#
  colnames(dd)[match(c("citizen", "geo"), colnames(dd))] <- txt[c("origins", "destinations"), lang]#
  colNums <- match(c("values", txt[c("origins", "destinations"), lang]), colnames(dd))#
#
  ps.chart <- parset(select(dd, colNums),#
    dimensions =  txt[c("origins", "destinations"), lang],#
    # use some JavaScript to inform parset that Freq has the value#
    # http://www.buildingwidgets.com/blog/2015/9/17/week-37-parsetr#
    value = htmlwidgets::JS("function(d){return d.values}"),#
    tension = 0.7, width = "100%", height = 400,#
    spacing = 18, duration = 300)#
#
  # overwite default padding#
  ps.chart$sizingPolicy$browser$padding <- 5#
#
  saveWidget(ps.chart, file = tmp_html, selfcontained = FALSE, libdir = "js")#
#
  swi_widget(tmp_html, output.html,#
    h2 = txt["title",lang],#
    descr = txt["description",lang],#
    h3 = txt["subtitle",lang],#
    source = paste0(txt["source",lang], ": ",#
      htmlLink("http://ec.europa.eu/eurostat/en/web/products-datasets/-/MIGR_ASYAPPCTZM",#
      txt["eurostat",lang])),#
    author = paste0("Duc-Quang Nguyen | ",#
      htmlLink("http://www.swissinfo.ch", "swissinfo.ch")),#
    footer = paste0("<strong>",#
      txt["footer.title",lang], "</strong><br>", txt["footer",lang])#
  )#
}
lang
setwd('/Users/nguyendu/swissinfo/2015_12_02_retrospectiveAsile')
dd <- df#
#
  tmp_html <- paste0("flow_EU_tmp_", lang, ".html")#
  output.html <- paste0("asylumApplicationsFlow_EU_", lang, ".html")#
#
  # rename origin / citizen country names#
  idx <- match(paste0("code.", gsub(" ", "", dd$citizen)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$citizen <- txt[idx, lang]#
#
  # rename destination / geo names#
  idx <- match(paste0("code.", gsub(" ", "", df$geo)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$geo <- txt[idx, lang]#
#
  # rename dimensions#
  colnames(dd)[match(c("citizen", "geo"), colnames(dd))] <- txt[c("origins", "destinations"), lang]#
  colNums <- match(c("values", txt[c("origins", "destinations"), lang]), colnames(dd))#
#
  ps.chart <- parset(select(dd, colNums),#
    dimensions =  txt[c("origins", "destinations"), lang],#
    # use some JavaScript to inform parset that Freq has the value#
    # http://www.buildingwidgets.com/blog/2015/9/17/week-37-parsetr#
    value = htmlwidgets::JS("function(d){return d.values}"),#
    tension = 0.7, width = "100%", height = -1400,#
    spacing = 18, duration = 300)#
#
  # overwite default padding#
  ps.chart$sizingPolicy$browser$padding <- 5#
#
  saveWidget(ps.chart, file = tmp_html, selfcontained = FALSE, libdir = "js")
setwd('/Users/nguyendu/swissinfo/2015_12_02_retrospectiveAsile')
dd <- df#
#
  tmp_html <- paste0("flow_EU_tmp_", lang, ".html")#
  output.html <- paste0("asylumApplicationsFlow_EU_", lang, ".html")#
#
  # rename origin / citizen country names#
  idx <- match(paste0("code.", gsub(" ", "", dd$citizen)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$citizen <- txt[idx, lang]#
#
  # rename destination / geo names#
  idx <- match(paste0("code.", gsub(" ", "", df$geo)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$geo <- txt[idx, lang]#
#
  # rename dimensions#
  colnames(dd)[match(c("citizen", "geo"), colnames(dd))] <- txt[c("origins", "destinations"), lang]#
  colNums <- match(c("values", txt[c("origins", "destinations"), lang]), colnames(dd))#
#
  ps.chart <- parset(select(dd, colNums),#
    dimensions =  txt[c("origins", "destinations"), lang],#
    # use some JavaScript to inform parset that Freq has the value#
    # http://www.buildingwidgets.com/blog/2015/9/17/week-37-parsetr#
    value = htmlwidgets::JS("function(d){return d.values}"),#
    tension = 0.7, width = "100%", height = 400,#
    spacing = 18, duration = 300)#
#
  # overwite default padding#
  ps.chart$sizingPolicy$browser$padding <- 5#
#
  saveWidget(ps.chart, file = tmp_html, selfcontained = FALSE, libdir = "js")
setwd('/Users/nguyendu/swissinfo/2015_12_02_retrospectiveAsile')
dd <- df#
#
  tmp_html <- paste0("flow_EU_tmp_", lang, ".html")#
  output.html <- paste0("asylumApplicationsFlow_EU_", lang, ".html")#
#
  # rename origin / citizen country names#
  idx <- match(paste0("code.", gsub(" ", "", dd$citizen)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$citizen <- txt[idx, lang]#
#
  # rename destination / geo names#
  idx <- match(paste0("code.", gsub(" ", "", df$geo)), rownames(txt))#
  stopifnot(all(!is.na(idx)))#
  dd$geo <- txt[idx, lang]#
#
  # rename dimensions#
  colnames(dd)[match(c("citizen", "geo"), colnames(dd))] <- txt[c("origins", "destinations"), lang]#
  colNums <- match(c("values", txt[c("origins", "destinations"), lang]), colnames(dd))#
#
  ps.chart <- parset(select(dd, colNums),#
    dimensions =  txt[c("origins", "destinations"), lang],#
    # use some JavaScript to inform parset that Freq has the value#
    # http://www.buildingwidgets.com/blog/2015/9/17/week-37-parsetr#
    value = htmlwidgets::JS("function(d){return d.values}"),#
    tension = 0.7, width = "100%", height = -400,#
    spacing = 18, duration = 300)#
#
  # overwite default padding#
  ps.chart$sizingPolicy$browser$padding <- 5#
#
  saveWidget(ps.chart, file = tmp_html, selfcontained = FALSE, libdir = "js")
